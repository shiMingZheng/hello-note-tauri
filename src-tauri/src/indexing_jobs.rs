// src-tauri/src/indexing_jobs.rs
// CheetahNote å¼‚æ­¥ç´¢å¼•ä»»åŠ¡ç³»ç»Ÿ
use crossbeam_channel::{unbounded, Sender, Receiver};
use once_cell::sync::Lazy;
use serde::{Serialize, Deserialize};
use std::sync::Arc;
use tantivy::Index;
use r2d2::Pool;
use r2d2_sqlite::SqliteConnectionManager;
use rusqlite::{params, OptionalExtension}; // [ä¿®å¤] æ·»åŠ  OptionalExtension
use anyhow::Result;
use crate::database::DbPool;
use std::sync::Mutex;
use std::collections::HashMap;
use std::collections::HashSet;
use std::time::{SystemTime, Duration};


// ============================================================================
// [æ–°å¢] å…¨å±€è¿½è¸ªå™¨: ä¸‰å±‚é˜²æŠ¤æœºåˆ¶
// ============================================================================

pub struct SaveTracker {
    /// Layer 1: ç¬æ—¶é” - æ­£åœ¨ä¿å­˜çš„æ–‡ä»¶ (ç”Ÿå‘½å‘¨æœŸ: ä¿å­˜å¼€å§‹â†’å†™å…¥å®Œæˆ)
    pub files_currently_saving: Mutex<HashSet<String>>,
    
    /// Layer 2: ç´¢å¼•æ ‡è®° - æ­£åœ¨ç´¢å¼•çš„æ–‡ä»¶ (ç”Ÿå‘½å‘¨æœŸ: ç´¢å¼•å¼€å§‹â†’ç´¢å¼•å®Œæˆ)
    pub files_currently_indexing: Mutex<HashSet<String>>,
    
    /// Layer 2 è¾…åŠ©: ç´¢å¼•å¼€å§‹æ—¶é—´ (ç”¨äºè¶…æ—¶æ£€æµ‹)
    pub indexing_start_times: Mutex<HashMap<String, SystemTime>>,
    
    /// Layer 3: æ—¶é—´æˆ³åœ°å›¾ - å·²çŸ¥çš„å†™å…¥æ—¶é—´ (ç”Ÿå‘½å‘¨æœŸ: åº”ç”¨è¿è¡ŒæœŸé—´)
    pub known_write_times: Mutex<HashMap<String, SystemTime>>,
    
    /// è¶…æ—¶æ—¶é•¿
    pub indexing_timeout: Duration,
	/// å¾…åˆ é™¤é˜Ÿåˆ—æ”¹ä¸ºï¼šå¯èƒ½æ˜¯é‡å‘½åçš„æ—§è·¯å¾„ (è·¯å¾„ -> æ£€æµ‹æ—¶é—´)
    pub potential_rename_sources: Mutex<HashMap<String, SystemTime>>,
    
    /// é‡å‘½åæ£€æµ‹çª—å£ (é»˜è®¤ 500msï¼Œå› ä¸ºå¤–éƒ¨é‡å‘½åå¯èƒ½ç¨æ…¢)
    pub rename_detection_window: Duration,

	pub files_currently_deleting: Mutex<HashSet<String>>,
    //
    pub known_delete_times: Mutex<HashMap<String, SystemTime>>,
}

impl SaveTracker {
    pub fn new() -> Self {
        Self {
            files_currently_saving: Mutex::new(HashSet::new()),
            files_currently_indexing: Mutex::new(HashSet::new()),
            indexing_start_times: Mutex::new(HashMap::new()),
            known_write_times: Mutex::new(HashMap::new()),
            indexing_timeout: Duration::from_secs(30),
			potential_rename_sources: Mutex::new(HashMap::new()),
            rename_detection_window: Duration::from_millis(500),
			// â­ åˆå§‹åŒ–æ–°å­—æ®µ
			files_currently_deleting: Mutex::new(HashSet::new()),
			known_delete_times: Mutex::new(HashMap::new()),
        }
    }
	

	/// æ ‡è®°å¯èƒ½æ˜¯é‡å‘½åçš„æ—§è·¯å¾„
	pub fn mark_potential_rename_source(&self, path: String) {
		let mut sources = self.potential_rename_sources.lock().unwrap();
		println!("â³ [é‡å‘½åæ£€æµ‹] æ ‡è®°æ½œåœ¨æ—§è·¯å¾„: {}", path);  // âœ… å…ˆæ‰“å°
		sources.insert(path, SystemTime::now());  // âœ… å†æ’å…¥
	}
    
    /// æŸ¥æ‰¾æœ€è¿‘çš„æ½œåœ¨é‡å‘½åæºï¼ˆ500mså†…ï¼‰
    pub fn find_recent_rename_source(&self) -> Option<String> {
        let now = SystemTime::now();
        let sources = self.potential_rename_sources.lock().unwrap();
        
        // æŸ¥æ‰¾æœ€è¿‘çš„ä¸€ä¸ªï¼ˆé€šå¸¸é‡å‘½åäº‹ä»¶ä¼šå¾ˆæ¥è¿‘ï¼‰
        sources.iter()
            .filter(|(_, time)| {
                now.duration_since(**time).unwrap_or(Duration::from_secs(999)) 
                    < self.rename_detection_window
            })
            .max_by_key(|(_, time)| *time)
            .map(|(path, _)| path.clone())
    }
    
    /// ç¡®è®¤é‡å‘½åå¹¶ç§»é™¤æ ‡è®°
    pub fn confirm_rename(&self, old_path: &str) {
        let mut sources = self.potential_rename_sources.lock().unwrap();
        sources.remove(old_path);
        println!("âœ… [é‡å‘½åæ£€æµ‹] ç¡®è®¤é‡å‘½å: {}", old_path);
    }
    
    /// æ¸…ç†è¿‡æœŸçš„é‡å‘½åæºæ ‡è®°
    pub fn cleanup_expired_rename_sources(&self) {
        let now = SystemTime::now();
        let mut sources = self.potential_rename_sources.lock().unwrap();
        
        sources.retain(|path, time| {
            let elapsed = now.duration_since(*time).unwrap_or(Duration::from_secs(0));
            if elapsed > self.rename_detection_window {
                println!("â±ï¸ [é‡å‘½åæ£€æµ‹] æ¸…ç†è¿‡æœŸæ ‡è®°: {}", path);
                false
            } else {
                true
            }
        });
    }
    
    /// æ¸…ç†è¶…æ—¶çš„ç´¢å¼•æ ‡è®°
    pub fn cleanup_timeout_markerscleanup_timeout_markers(&self) {
        let now = SystemTime::now();
        let mut indexing = self.files_currently_indexing.lock().unwrap();
        let mut times = self.indexing_start_times.lock().unwrap();
        
        times.retain(|path, start_time| {
            if now.duration_since(*start_time).unwrap_or(Duration::from_secs(0)) > self.indexing_timeout {
                println!("âš ï¸ [è¿½è¸ªå™¨] æ¸…ç†è¶…æ—¶ç´¢å¼•æ ‡è®°: {}", path);
                indexing.remove(path);
                false
            } else {
                true
            }
        });
    }
}

// å…¨å±€è¿½è¸ªå™¨å®ä¾‹
pub static SAVE_TRACKER: Lazy<SaveTracker> = Lazy::new(|| SaveTracker::new());

// [æ–°å¢] å…¨å±€æ•°æ®åº“è¿æ¥æ± å¼•ç”¨
pub static DB_POOL_REF: Lazy<Mutex<Option<DbPool>>> = Lazy::new(|| Mutex::new(None));
// [æ–°å¢] åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± å¼•ç”¨
pub fn set_db_pool(pool: DbPool) {
    *DB_POOL_REF.lock().unwrap() = Some(pool);
}


use crate::search_core::{
    update_document_index,
    update_document_index_for_rename,
    delete_document
};

// ============================================================================
// 1. ä»»åŠ¡è½½è·å®šä¹‰
// ============================================================================

#[derive(Serialize, Deserialize, Debug, Clone)]
pub enum JobPayload {
    /// æ›´æ–°æˆ–ä¿å­˜æ–‡ä»¶
    UpdateOrSave { 
        root_path: String,
        relative_path: String 
    },
    
    /// é‡å‘½åæˆ–ç§»åŠ¨æ–‡ä»¶
    RenameOrMove { 
        root_path: String,
        old_relative_path: String,
        new_relative_path: String 
    },
    
    /// åˆ é™¤æ–‡ä»¶
    Delete { 
        relative_path: String 
    },
}

// ============================================================================
// 2. ç´¢å¼•ä»»åŠ¡ç»“æ„
// ============================================================================

#[derive(Debug)]
pub struct IndexingJob {
    /// æ•°æ®åº“IDï¼ˆä»æ•°æ®åº“åŠ è½½çš„ä»»åŠ¡æœ‰IDï¼Œå®æ—¶ä»»åŠ¡ä¸ºNoneï¼‰
    pub db_id: Option<i64>,
    
    /// ä»»åŠ¡è½½è·
    pub payload: JobPayload,
}

// ============================================================================
// 3. æ§åˆ¶ä¿¡å·
// ============================================================================

pub enum ControlSignal {
    Job(IndexingJob),
    Shutdown,
}

// ============================================================================
// 4. å…¨å±€é€šé“
// ============================================================================

pub static JOB_CHANNEL: Lazy<(Sender<ControlSignal>, Receiver<ControlSignal>)> = 
    Lazy::new(|| unbounded());

// ============================================================================
// 5. åå° Worker å¯åŠ¨å‡½æ•°
// ============================================================================

pub fn start_background_worker(
    db_pool: Pool<SqliteConnectionManager>,
    index: Arc<Index>,
) -> std::thread::JoinHandle<()> {
    let receiver = JOB_CHANNEL.1.clone();

    std::thread::spawn(move || {
        println!("ğŸ” [ç´¢å¼•Worker] å¯åŠ¨æˆåŠŸ");

        // æ­¥éª¤A: å¤„ç†æ•°æ®åº“ä¸­çš„é—ç•™ä»»åŠ¡
        if let Err(e) = process_pending_db_jobs(&db_pool, &index) {
            eprintln!("âŒ [ç´¢å¼•Worker] å¤„ç†é—ç•™ä»»åŠ¡å¤±è´¥: {}", e);
        }

        // æ­¥éª¤B: è¿›å…¥ä¸»å¾ªç¯ï¼Œç›‘å¬å®æ—¶ä»»åŠ¡
        loop {
            match receiver.recv() {
                Ok(ControlSignal::Job(job)) => {
					  println!("ğŸ” [ç´¢å¼•Worker] æ¥æ”¶åˆ°ä»»åŠ¡: {:?}", job.payload); // âœ… æ·»åŠ è¿™è¡Œ
                    // å¤„ç†ä»»åŠ¡
                    let result = process_job(&db_pool, &index, &job.payload);

                    if let Err(e) = result {
                        eprintln!(
                            "âŒ [ç´¢å¼•Worker] ä»»åŠ¡å¤„ç†å¤±è´¥: {:?}. é”™è¯¯: {}",
                            job.payload, e
                        );
                        
                        // æŒä¹…åŒ–å¤±è´¥çš„ä»»åŠ¡
                        if let Err(persist_err) = persist_failed_job_to_db(&db_pool, &job, &e.to_string()) {
                            eprintln!(
                                "âŒ [ç´¢å¼•Worker] æŒä¹…åŒ–å¤±è´¥ä»»åŠ¡æ—¶å‡ºé”™: {}",
                                persist_err
                            );
                        }
                    } else if let Some(id) = job.db_id {
                        // å¦‚æœä»»åŠ¡æ¥è‡ªæ•°æ®åº“ï¼ŒæˆåŠŸååˆ é™¤
                        if let Err(del_err) = delete_job_from_db(&db_pool, id) {
                            eprintln!(
                                "âš ï¸ [ç´¢å¼•Worker] åˆ é™¤å·²å®Œæˆä»»åŠ¡å¤±è´¥ (ID={}): {}",
                                id, del_err
                            );
                        } else {
                            println!("âœ… [ç´¢å¼•Worker] ä»»åŠ¡å®Œæˆå¹¶æ¸…ç† (ID={})", id);
                        }
                    } else {
                        println!("âœ… [ç´¢å¼•Worker] å®æ—¶ä»»åŠ¡å®Œæˆ");
                    }
                }
                Ok(ControlSignal::Shutdown) => {
                    println!("ğŸ›‘ [ç´¢å¼•Worker] æ¥æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...");
                    break;
                }
                Err(e) => {
                    eprintln!("âŒ [ç´¢å¼•Worker] æ¥æ”¶ä»»åŠ¡æ—¶å‡ºé”™: {}", e);
                    break;
                }
            }
        }

        println!("ğŸ” [ç´¢å¼•Worker] å·²å®‰å…¨é€€å‡º");
    })
}

// ============================================================================
// 6. ä»»åŠ¡å¤„ç†é€»è¾‘
// ============================================================================

fn process_job(
    db_pool: &Pool<SqliteConnectionManager>,
    index: &Arc<Index>,
    payload: &JobPayload,
) -> Result<()> {
    use std::path::Path;
    use std::fs::metadata;
    use std::time::UNIX_EPOCH;

    match payload {
        JobPayload::UpdateOrSave { root_path, relative_path } => {
			println!("ğŸ” [ç´¢å¼•] æ›´æ–°/ä¿å­˜: {}", relative_path);
			
			// æ­¥éª¤1: æ‰§è¡Œç´¢å¼•
			update_document_index(
				index,
				db_pool,
				Path::new(root_path),
				Path::new(relative_path),
			)?;
			
			// æ­¥éª¤2: âœ… æ›´æ–° files è¡¨çš„ indexed å’Œ last_modified
			let conn = db_pool.get()?;
			let absolute_path = crate::commands::path_utils::to_absolute_path(
				Path::new(root_path),
				Path::new(relative_path)
			);
			
			// âœ… è·å– mtimeï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨å½“å‰æ—¶é—´æˆ³
			let mtime = if let Ok(meta) = metadata(&absolute_path) {
				if let Ok(modified) = meta.modified() {
					if let Ok(duration) = modified.duration_since(UNIX_EPOCH) {
						duration.as_secs() as i64
					} else {
						// å¦‚æœæ—¶é—´æ—©äº UNIX_EPOCHï¼Œä½¿ç”¨å½“å‰æ—¶é—´
						std::time::SystemTime::now()
							.duration_since(UNIX_EPOCH)
							.unwrap()
							.as_secs() as i64
					}
				} else {
					// è·å–ä¿®æ”¹æ—¶é—´å¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
					std::time::SystemTime::now()
						.duration_since(UNIX_EPOCH)
						.unwrap()
						.as_secs() as i64
				}
			} else {
				// è¯»å–æ–‡ä»¶å…ƒæ•°æ®å¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
				eprintln!("âš ï¸ [ç´¢å¼•] æ— æ³•è·å–æ–‡ä»¶å…ƒæ•°æ®: {}", absolute_path.display());
				std::time::SystemTime::now()
					.duration_since(UNIX_EPOCH)
					.unwrap()
					.as_secs() as i64
			};
			
			// âœ… æ— è®ºå¦‚ä½•éƒ½è¦æ›´æ–° indexed çŠ¶æ€
			conn.execute(
				"UPDATE files SET indexed = 1, last_modified = ?1 WHERE path = ?2",
				params![mtime, relative_path],
			)?;
			  // âœ… Layer 2: ç´¢å¼•å®Œæˆ,ç§»é™¤æ ‡è®°
			{
				let mut indexing = SAVE_TRACKER.files_currently_indexing.lock().unwrap();
				let mut times = SAVE_TRACKER.indexing_start_times.lock().unwrap();
				
				indexing.remove(relative_path);
				times.remove(relative_path);
				
				println!("âœ… [ç´¢å¼•] å·²æ¸…é™¤ç´¢å¼•æ ‡è®°: {}", relative_path);
			}
			
			// âœ… Layer 3: æ›´æ–°å·²çŸ¥æ—¶é—´æˆ³
			{
				let absolute_path = crate::commands::path_utils::to_absolute_path(
					Path::new(root_path),
					Path::new(relative_path)
				);
				
				if let Ok(meta) = metadata(&absolute_path) {
					if let Ok(modified) = meta.modified() {
						let mut known_times = SAVE_TRACKER.known_write_times.lock().unwrap();
						known_times.insert(relative_path.clone(), modified);
						println!("âœ… [æ—¶é—´æˆ³] å·²è®°å½•: {}", relative_path);
					}
				}
			}

			println!("âœ… [ç´¢å¼•] å·²æ›´æ–°æ•°æ®åº“çŠ¶æ€: {} (mtime={})", relative_path, mtime);
		}
        
        JobPayload::RenameOrMove { root_path, old_relative_path, new_relative_path } => {
			println!(
				"ğŸ” [ç´¢å¼•] é‡å‘½å: {} -> {}",
				old_relative_path, new_relative_path
			);
			
			// æ­¥éª¤1: æ‰§è¡Œç´¢å¼•
			update_document_index_for_rename(
				index,
				db_pool,
				Path::new(root_path),
				Path::new(old_relative_path),
				Path::new(new_relative_path),
			)?;
			
			// æ­¥éª¤2: æ›´æ–°æ•°æ®åº“
			let conn = db_pool.get()?;
			let absolute_path = crate::commands::path_utils::to_absolute_path(
				Path::new(root_path),
				Path::new(new_relative_path)
			);
			
			// âœ… è·å– mtimeï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨å½“å‰æ—¶é—´æˆ³
			let mtime = if let Ok(meta) = metadata(&absolute_path) {
				if let Ok(modified) = meta.modified() {
					if let Ok(duration) = modified.duration_since(UNIX_EPOCH) {
						duration.as_secs() as i64
					} else {
						eprintln!("âš ï¸ [ç´¢å¼•] æ–‡ä»¶æ—¶é—´æ—©äº UNIX_EPOCH: {}", absolute_path.display());
						std::time::SystemTime::now()
							.duration_since(UNIX_EPOCH)
							.unwrap()
							.as_secs() as i64
					}
				} else {
					eprintln!("âš ï¸ [ç´¢å¼•] æ— æ³•è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´: {}", absolute_path.display());
					std::time::SystemTime::now()
						.duration_since(UNIX_EPOCH)
						.unwrap()
						.as_secs() as i64
				}
			} else {
				eprintln!("âš ï¸ [ç´¢å¼•] æ— æ³•è·å–æ–‡ä»¶å…ƒæ•°æ®: {}", absolute_path.display());
				std::time::SystemTime::now()
					.duration_since(UNIX_EPOCH)
					.unwrap()
					.as_secs() as i64
			};
			
			conn.execute(
				"UPDATE files SET indexed = 1, last_modified = ?1 WHERE path = ?2",
				params![mtime, new_relative_path],
			)?;
			
		// âœ… Layer 2: ç´¢å¼•å®Œæˆ,ç§»é™¤æ—§è·¯å¾„å’Œæ–°è·¯å¾„çš„æ ‡è®°
			{
				let mut indexing = SAVE_TRACKER.files_currently_indexing.lock().unwrap();
				let mut times = SAVE_TRACKER.indexing_start_times.lock().unwrap();
				
				indexing.remove(old_relative_path);
				indexing.remove(new_relative_path);
				times.remove(old_relative_path);
				times.remove(new_relative_path);
				
				println!("âœ… [ç´¢å¼•] å·²æ¸…é™¤ç´¢å¼•æ ‡è®°: {} -> {}", old_relative_path, new_relative_path);
			}
			
			// âœ… Layer 3: æ›´æ–°å·²çŸ¥æ—¶é—´æˆ³ (ä½¿ç”¨ new_relative_path)
			{
				let absolute_path = crate::commands::path_utils::to_absolute_path(
					Path::new(root_path),
					Path::new(new_relative_path)
				);
				
				if let Ok(meta) = metadata(&absolute_path) {
					if let Ok(modified) = meta.modified() {
						let mut known_times = SAVE_TRACKER.known_write_times.lock().unwrap();
						known_times.insert(new_relative_path.clone(), modified);
						println!("âœ… [æ—¶é—´æˆ³] å·²è®°å½•: {}", new_relative_path);
					}
				}
			}						

			
			println!("âœ… [ç´¢å¼•] å·²æ›´æ–°æ•°æ®åº“çŠ¶æ€: {} (mtime={})", new_relative_path, mtime);
		}
        
        JobPayload::Delete { relative_path } => {
            println!("ğŸ” [ç´¢å¼•] åˆ é™¤: {}", relative_path);
            
            // åˆ é™¤æ“ä½œä¸éœ€è¦æ›´æ–° files è¡¨,å› ä¸ºè®°å½•å·²ç»åœ¨ fs.rs ä¸­è¢«åˆ é™¤äº†
            delete_document(index, relative_path)?;
        }
    }

    Ok(())
}

// ============================================================================
// 7. æ•°æ®åº“é˜Ÿåˆ—è¾…åŠ©å‡½æ•°
// ============================================================================

/// å¤„ç†æ•°æ®åº“ä¸­æ‰€æœ‰å¾…å¤„ç†çš„ä»»åŠ¡
/// å¤„ç†æ•°æ®åº“ä¸­æ‰€æœ‰å¾…å¤„ç†çš„ä»»åŠ¡
fn process_pending_db_jobs(
    db_pool: &Pool<SqliteConnectionManager>,
    index: &Arc<Index>,
) -> Result<()> {
    let conn = db_pool.get()?;
    
    println!("ğŸ” [ç´¢å¼•Worker] æ£€æŸ¥é—ç•™ä»»åŠ¡...");

    loop {
        // æŸ¥è¯¢ä¸€æ¡å¾…å¤„ç†çš„ä»»åŠ¡
        let job_opt: Option<(i64, String)> = conn
            .query_row(
                "SELECT id, payload FROM indexing_jobs 
                 WHERE status = 'pending' AND retry_count < max_retries
                 ORDER BY created_at ASC LIMIT 1",
                [],
                |row| Ok((row.get(0)?, row.get(1)?)), // [ä¿®å¤] ç›´æ¥åœ¨è¿™é‡Œè¿”å› String
            )
            .optional()?;

        match job_opt {
            Some((id, payload_json)) => { // [ä¿®å¤] payload_json ç°åœ¨æ˜¯ String ç±»å‹
                println!("ğŸ” [ç´¢å¼•Worker] å¤„ç†é—ç•™ä»»åŠ¡ ID={}", id);

                // ååºåˆ—åŒ–è½½è·
                let payload: JobPayload = serde_json::from_str(&payload_json)?;

                // å¤„ç†ä»»åŠ¡
                let result = process_job(db_pool, index, &payload);

                if let Err(e) = result {
                    eprintln!("âŒ [ç´¢å¼•Worker] é—ç•™ä»»åŠ¡å¤±è´¥ ID={}: {}", id, e);

                    // å¢åŠ é‡è¯•æ¬¡æ•°
                    conn.execute(
                        "UPDATE indexing_jobs 
                         SET retry_count = retry_count + 1,
                             last_error = ?1,
                             updated_at = CURRENT_TIMESTAMP
                         WHERE id = ?2",
                        params![e.to_string(), id],
                    )?;

                    // æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°
                    let retry_count: i32 = conn.query_row(
                        "SELECT retry_count FROM indexing_jobs WHERE id = ?1",
                        params![id],
                        |row| row.get(0),
                    )?;

                    let max_retries: i32 = conn.query_row(
                        "SELECT max_retries FROM indexing_jobs WHERE id = ?1",
                        params![id],
                        |row| row.get(0),
                    )?;

                    if retry_count >= max_retries {
                        conn.execute(
                            "UPDATE indexing_jobs 
                             SET status = 'failed',
                                 updated_at = CURRENT_TIMESTAMP
                             WHERE id = ?1",
                            params![id],
                        )?;
                        eprintln!("âš ï¸ [ç´¢å¼•Worker] ä»»åŠ¡ ID={} å·²æ ‡è®°ä¸ºå¤±è´¥", id);
                    }
                } else {
                    // æˆåŠŸååˆ é™¤ä»»åŠ¡
                    delete_job_from_db(db_pool, id)?;
                    println!("âœ… [ç´¢å¼•Worker] é—ç•™ä»»åŠ¡å®Œæˆ ID={}", id);
                }
            }
            None => {
                println!("âœ… [ç´¢å¼•Worker] æ‰€æœ‰é—ç•™ä»»åŠ¡å¤„ç†å®Œæˆ");
                break;
            }
        }
    }

    Ok(())
}

/// æŒä¹…åŒ–å¤±è´¥çš„ä»»åŠ¡åˆ°æ•°æ®åº“
/// æŒä¹…åŒ–å¤±è´¥çš„ä»»åŠ¡åˆ°æ•°æ®åº“
fn persist_failed_job_to_db(
    db_pool: &Pool<SqliteConnectionManager>,
    job: &IndexingJob,
    error_msg: &str,
) -> Result<()> {
    let conn = db_pool.get()?;
    let payload_json = serde_json::to_string(&job.payload)?;

    if let Some(id) = job.db_id {
        // æ›´æ–°ç°æœ‰ä»»åŠ¡
        conn.execute(
            "UPDATE indexing_jobs 
             SET retry_count = retry_count + 1,
                 last_error = ?1,
                 updated_at = CURRENT_TIMESTAMP
             WHERE id = ?2",
            params![error_msg, id],
        )?;
    } else {
        // æ’å…¥æ–°ä»»åŠ¡
        conn.execute(
            "INSERT INTO indexing_jobs (payload, status, last_error)
             VALUES (?1, 'pending', ?2)",
            params![payload_json, error_msg],
        )?;
    }

    Ok(())
}

/// ä»æ•°æ®åº“åˆ é™¤å·²å®Œæˆçš„ä»»åŠ¡
fn delete_job_from_db(
    db_pool: &Pool<SqliteConnectionManager>,
    job_id: i64,
) -> Result<()> {
    let conn = db_pool.get()?;
    conn.execute("DELETE FROM indexing_jobs WHERE id = ?1", params![job_id])?;
    Ok(())
}

// ============================================================================
// 8. å…¬å…± APIï¼šå‘é€ç´¢å¼•ä»»åŠ¡
// ============================================================================

/// å‘é€æ›´æ–°/ä¿å­˜ä»»åŠ¡
/// å‘é€æ›´æ–°/ä¿å­˜ä»»åŠ¡
pub fn dispatch_update_job(root_path: String, relative_path: String) -> Result<()> {
    // âœ… Layer 2: æ¸…ç†è¶…æ—¶æ ‡è®°
    SAVE_TRACKER.cleanup_timeout_markers();
    
    // âœ… Layer 2: æ£€æŸ¥æ˜¯å¦æ­£åœ¨ç´¢å¼•
    {
        let indexing = SAVE_TRACKER.files_currently_indexing.lock().unwrap();
        if indexing.contains(&relative_path) {
            println!("â­ï¸ [ç´¢å¼•å»é‡] è·³è¿‡é‡å¤ä»»åŠ¡: {} (æ­£åœ¨ç´¢å¼•ä¸­)", relative_path);
            return Ok(()); // ç›´æ¥è¿”å›,ä¸åˆ†å‘ä»»åŠ¡
        }
    }
    
    // âœ… Layer 2: æ ‡è®°ä¸º"ç´¢å¼•ä¸­"
    {
        let mut indexing = SAVE_TRACKER.files_currently_indexing.lock().unwrap();
        let mut times = SAVE_TRACKER.indexing_start_times.lock().unwrap();
        
        indexing.insert(relative_path.clone());
        times.insert(relative_path.clone(), SystemTime::now());
    }
    
    let payload = JobPayload::UpdateOrSave {
        root_path,
        relative_path,
    };
    
    // [å…³é”®ä¿®æ”¹] å…ˆæŒä¹…åŒ–åˆ°æ•°æ®åº“
    let job_id = persist_job_to_db(&payload)?;
    
    // ç„¶åå‘é€åˆ°å†…å­˜é€šé“
    let job = IndexingJob {
        db_id: Some(job_id),
        payload,
    };
    
    JOB_CHANNEL
        .0
        .send(ControlSignal::Job(job))
        .map_err(|e| anyhow::anyhow!("å‘é€ç´¢å¼•ä»»åŠ¡å¤±è´¥: {}", e))?;

    Ok(())
}

/// å‘é€é‡å‘½åä»»åŠ¡
pub fn dispatch_rename_job(
    root_path: String,
    old_relative_path: String,
    new_relative_path: String,
) -> Result<()> {
    let payload = JobPayload::RenameOrMove {
        root_path,
        old_relative_path,
        new_relative_path,
    };
    
    // [å…³é”®ä¿®æ”¹] å…ˆæŒä¹…åŒ–åˆ°æ•°æ®åº“
    let job_id = persist_job_to_db(&payload)?;
    
    // ç„¶åå‘é€åˆ°å†…å­˜é€šé“
    let job = IndexingJob {
        db_id: Some(job_id),
        payload,
    };

    JOB_CHANNEL
        .0
        .send(ControlSignal::Job(job))
        .map_err(|e| anyhow::anyhow!("å‘é€é‡å‘½åä»»åŠ¡å¤±è´¥: {}", e))?;

    Ok(())
}


/// å‘é€åˆ é™¤ä»»åŠ¡
pub fn dispatch_delete_job(relative_path: String) -> Result<()> {
	  // âœ… åˆ é™¤æ“ä½œ: å¼ºåˆ¶æ¸…é™¤æ‰€æœ‰ç›¸å…³æ ‡è®°
    {
        let mut indexing = SAVE_TRACKER.files_currently_indexing.lock().unwrap();
        let mut times = SAVE_TRACKER.indexing_start_times.lock().unwrap();
        let mut saving = SAVE_TRACKER.files_currently_saving.lock().unwrap();
        
        indexing.remove(&relative_path);
        times.remove(&relative_path);
        saving.remove(&relative_path);
    }
    

    let payload = JobPayload::Delete { relative_path };
    
    // [å…³é”®ä¿®æ”¹] å…ˆæŒä¹…åŒ–åˆ°æ•°æ®åº“
    let job_id = persist_job_to_db(&payload)?;
    
    // ç„¶åå‘é€åˆ°å†…å­˜é€šé“
    let job = IndexingJob {
        db_id: Some(job_id),
        payload,
    };

    JOB_CHANNEL
        .0
        .send(ControlSignal::Job(job))
        .map_err(|e| anyhow::anyhow!("å‘é€åˆ é™¤ä»»åŠ¡å¤±è´¥: {}", e))?;

    Ok(())
}
// ============================================================================
// [æ–°å¢] æŒä¹…åŒ–å‡½æ•°
// ============================================================================

/// ç«‹å³æŒä¹…åŒ–ä»»åŠ¡åˆ°æ•°æ®åº“ï¼Œè¿”å›ä»»åŠ¡ID
fn persist_job_to_db(payload: &JobPayload) -> Result<i64> {
    let db_pool_lock = DB_POOL_REF.lock().unwrap();
    let db_pool = db_pool_lock.as_ref()
        .ok_or_else(|| anyhow::anyhow!("æ•°æ®åº“è¿æ¥æ± æœªåˆå§‹åŒ–"))?;
    
    let conn = db_pool.get()?;
    let payload_json = serde_json::to_string(payload)?;
    
    conn.execute(
        "INSERT INTO indexing_jobs (payload, status, retry_count)
         VALUES (?1, 'pending', 0)",
        params![payload_json],
    )?;
    
    let job_id = conn.last_insert_rowid();
    Ok(job_id)
}
