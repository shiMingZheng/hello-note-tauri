// src-tauri/src/indexing_jobs.rs
// CheetahNote å¼‚æ­¥ç´¢å¼•ä»»åŠ¡ç³»ç»Ÿ
use crossbeam_channel::{unbounded, Sender, Receiver};
use once_cell::sync::Lazy;
use serde::{Serialize, Deserialize};
use std::sync::Arc;
use tantivy::Index;
use r2d2::Pool;
use r2d2_sqlite::SqliteConnectionManager;
use rusqlite::{params, OptionalExtension}; // [ä¿®å¤] æ·»åŠ  OptionalExtension
use anyhow::Result;
use crate::database::DbPool;
use std::sync::Mutex;
use crate::commands::path_utils::to_absolute_path;
use std::fs::metadata;
use std::time::UNIX_EPOCH;



// [æ–°å¢] å…¨å±€æ•°æ®åº“è¿æ¥æ± å¼•ç”¨
pub static DB_POOL_REF: Lazy<Mutex<Option<DbPool>>> = Lazy::new(|| Mutex::new(None));
// [æ–°å¢] åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± å¼•ç”¨
pub fn set_db_pool(pool: DbPool) {
    *DB_POOL_REF.lock().unwrap() = Some(pool);
}


use crate::search_core::{
    update_document_index,
    update_document_index_for_rename,
    delete_document
};

// ============================================================================
// 1. ä»»åŠ¡è½½è·å®šä¹‰
// ============================================================================

#[derive(Serialize, Deserialize, Debug, Clone)]
pub enum JobPayload {
    /// æ›´æ–°æˆ–ä¿å­˜æ–‡ä»¶
    UpdateOrSave { 
        root_path: String,
        relative_path: String 
    },
    
    /// é‡å‘½åæˆ–ç§»åŠ¨æ–‡ä»¶
    RenameOrMove { 
        root_path: String,
        old_relative_path: String,
        new_relative_path: String 
    },
    
    /// åˆ é™¤æ–‡ä»¶
    Delete { 
        relative_path: String 
    },
}

// ============================================================================
// 2. ç´¢å¼•ä»»åŠ¡ç»“æ„
// ============================================================================

#[derive(Debug)]
pub struct IndexingJob {
    /// æ•°æ®åº“IDï¼ˆä»æ•°æ®åº“åŠ è½½çš„ä»»åŠ¡æœ‰IDï¼Œå®æ—¶ä»»åŠ¡ä¸ºNoneï¼‰
    pub db_id: Option<i64>,
    
    /// ä»»åŠ¡è½½è·
    pub payload: JobPayload,
}

// ============================================================================
// 3. æ§åˆ¶ä¿¡å·
// ============================================================================

pub enum ControlSignal {
    Job(IndexingJob),
    Shutdown,
}

// ============================================================================
// 4. å…¨å±€é€šé“
// ============================================================================

pub static JOB_CHANNEL: Lazy<(Sender<ControlSignal>, Receiver<ControlSignal>)> = 
    Lazy::new(|| unbounded());

// ============================================================================
// 5. åå° Worker å¯åŠ¨å‡½æ•°
// ============================================================================

pub fn start_background_worker(
    db_pool: Pool<SqliteConnectionManager>,
    index: Arc<Index>,
) -> std::thread::JoinHandle<()> {
    let receiver = JOB_CHANNEL.1.clone();

    std::thread::spawn(move || {
        println!("ğŸ” [ç´¢å¼•Worker] å¯åŠ¨æˆåŠŸ");

        // æ­¥éª¤A: å¤„ç†æ•°æ®åº“ä¸­çš„é—ç•™ä»»åŠ¡
        if let Err(e) = process_pending_db_jobs(&db_pool, &index) {
            eprintln!("âŒ [ç´¢å¼•Worker] å¤„ç†é—ç•™ä»»åŠ¡å¤±è´¥: {}", e);
        }

        // æ­¥éª¤B: è¿›å…¥ä¸»å¾ªç¯ï¼Œç›‘å¬å®æ—¶ä»»åŠ¡
        loop {
            match receiver.recv() {
                Ok(ControlSignal::Job(job)) => {
					  println!("ğŸ” [ç´¢å¼•Worker] æ¥æ”¶åˆ°ä»»åŠ¡: {:?}", job.payload); // âœ… æ·»åŠ è¿™è¡Œ
                    // å¤„ç†ä»»åŠ¡
                    let result = process_job(&db_pool, &index, &job.payload);

                    if let Err(e) = result {
                        eprintln!(
                            "âŒ [ç´¢å¼•Worker] ä»»åŠ¡å¤„ç†å¤±è´¥: {:?}. é”™è¯¯: {}",
                            job.payload, e
                        );
                        
                        // æŒä¹…åŒ–å¤±è´¥çš„ä»»åŠ¡
                        if let Err(persist_err) = persist_failed_job_to_db(&db_pool, &job, &e.to_string()) {
                            eprintln!(
                                "âŒ [ç´¢å¼•Worker] æŒä¹…åŒ–å¤±è´¥ä»»åŠ¡æ—¶å‡ºé”™: {}",
                                persist_err
                            );
                        }
                    } else if let Some(id) = job.db_id {
                        // å¦‚æœä»»åŠ¡æ¥è‡ªæ•°æ®åº“ï¼ŒæˆåŠŸååˆ é™¤
                        if let Err(del_err) = delete_job_from_db(&db_pool, id) {
                            eprintln!(
                                "âš ï¸ [ç´¢å¼•Worker] åˆ é™¤å·²å®Œæˆä»»åŠ¡å¤±è´¥ (ID={}): {}",
                                id, del_err
                            );
                        } else {
                            println!("âœ… [ç´¢å¼•Worker] ä»»åŠ¡å®Œæˆå¹¶æ¸…ç† (ID={})", id);
                        }
                    } else {
                        println!("âœ… [ç´¢å¼•Worker] å®æ—¶ä»»åŠ¡å®Œæˆ");
                    }
                }
                Ok(ControlSignal::Shutdown) => {
                    println!("ğŸ›‘ [ç´¢å¼•Worker] æ¥æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...");
                    break;
                }
                Err(e) => {
                    eprintln!("âŒ [ç´¢å¼•Worker] æ¥æ”¶ä»»åŠ¡æ—¶å‡ºé”™: {}", e);
                    break;
                }
            }
        }

        println!("ğŸ” [ç´¢å¼•Worker] å·²å®‰å…¨é€€å‡º");
    })
}

// ============================================================================
// 6. ä»»åŠ¡å¤„ç†é€»è¾‘
// ============================================================================

fn process_job(
    db_pool: &Pool<SqliteConnectionManager>,
    index: &Arc<Index>,
    payload: &JobPayload,
) -> Result<()> {
    use std::path::Path;
    use std::fs::metadata;
    use std::time::UNIX_EPOCH;

    match payload {
        JobPayload::UpdateOrSave { root_path, relative_path } => {
			println!("ğŸ” [ç´¢å¼•] æ›´æ–°/ä¿å­˜: {}", relative_path);
			
			// æ­¥éª¤1: æ‰§è¡Œç´¢å¼•
			update_document_index(
				index,
				db_pool,
				Path::new(root_path),
				Path::new(relative_path),
			)?;
			
			// æ­¥éª¤2: âœ… æ›´æ–° files è¡¨çš„ indexed å’Œ last_modified
			let conn = db_pool.get()?;
			let absolute_path = crate::commands::path_utils::to_absolute_path(
				Path::new(root_path),
				Path::new(relative_path)
			);
			
			// âœ… è·å– mtimeï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨å½“å‰æ—¶é—´æˆ³
			let mtime = if let Ok(meta) = metadata(&absolute_path) {
				if let Ok(modified) = meta.modified() {
					if let Ok(duration) = modified.duration_since(UNIX_EPOCH) {
						duration.as_secs() as i64
					} else {
						// å¦‚æœæ—¶é—´æ—©äº UNIX_EPOCHï¼Œä½¿ç”¨å½“å‰æ—¶é—´
						std::time::SystemTime::now()
							.duration_since(UNIX_EPOCH)
							.unwrap()
							.as_secs() as i64
					}
				} else {
					// è·å–ä¿®æ”¹æ—¶é—´å¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
					std::time::SystemTime::now()
						.duration_since(UNIX_EPOCH)
						.unwrap()
						.as_secs() as i64
				}
			} else {
				// è¯»å–æ–‡ä»¶å…ƒæ•°æ®å¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
				eprintln!("âš ï¸ [ç´¢å¼•] æ— æ³•è·å–æ–‡ä»¶å…ƒæ•°æ®: {}", absolute_path.display());
				std::time::SystemTime::now()
					.duration_since(UNIX_EPOCH)
					.unwrap()
					.as_secs() as i64
			};
			
			// âœ… æ— è®ºå¦‚ä½•éƒ½è¦æ›´æ–° indexed çŠ¶æ€
			conn.execute(
				"UPDATE files SET indexed = 1, last_modified = ?1 WHERE path = ?2",
				params![mtime, relative_path],
			)?;
			
			println!("âœ… [ç´¢å¼•] å·²æ›´æ–°æ•°æ®åº“çŠ¶æ€: {} (mtime={})", relative_path, mtime);
		}
        
        JobPayload::RenameOrMove { root_path, old_relative_path, new_relative_path } => {
			println!(
				"ğŸ” [ç´¢å¼•] é‡å‘½å: {} -> {}",
				old_relative_path, new_relative_path
			);
			
			// æ­¥éª¤1: æ‰§è¡Œç´¢å¼•
			update_document_index_for_rename(
				index,
				db_pool,
				Path::new(root_path),
				Path::new(old_relative_path),
				Path::new(new_relative_path),
			)?;
			
			// æ­¥éª¤2: æ›´æ–°æ•°æ®åº“
			let conn = db_pool.get()?;
			let absolute_path = crate::commands::path_utils::to_absolute_path(
				Path::new(root_path),
				Path::new(new_relative_path)
			);
			
			// âœ… è·å– mtimeï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨å½“å‰æ—¶é—´æˆ³
			let mtime = if let Ok(meta) = metadata(&absolute_path) {
				if let Ok(modified) = meta.modified() {
					if let Ok(duration) = modified.duration_since(UNIX_EPOCH) {
						duration.as_secs() as i64
					} else {
						eprintln!("âš ï¸ [ç´¢å¼•] æ–‡ä»¶æ—¶é—´æ—©äº UNIX_EPOCH: {}", absolute_path.display());
						std::time::SystemTime::now()
							.duration_since(UNIX_EPOCH)
							.unwrap()
							.as_secs() as i64
					}
				} else {
					eprintln!("âš ï¸ [ç´¢å¼•] æ— æ³•è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´: {}", absolute_path.display());
					std::time::SystemTime::now()
						.duration_since(UNIX_EPOCH)
						.unwrap()
						.as_secs() as i64
				}
			} else {
				eprintln!("âš ï¸ [ç´¢å¼•] æ— æ³•è·å–æ–‡ä»¶å…ƒæ•°æ®: {}", absolute_path.display());
				std::time::SystemTime::now()
					.duration_since(UNIX_EPOCH)
					.unwrap()
					.as_secs() as i64
			};
			
			conn.execute(
				"UPDATE files SET indexed = 1, last_modified = ?1 WHERE path = ?2",
				params![mtime, new_relative_path],
			)?;
			
			println!("âœ… [ç´¢å¼•] å·²æ›´æ–°æ•°æ®åº“çŠ¶æ€: {} (mtime={})", new_relative_path, mtime);
		}
        
        JobPayload::Delete { relative_path } => {
            println!("ğŸ” [ç´¢å¼•] åˆ é™¤: {}", relative_path);
            
            // åˆ é™¤æ“ä½œä¸éœ€è¦æ›´æ–° files è¡¨,å› ä¸ºè®°å½•å·²ç»åœ¨ fs.rs ä¸­è¢«åˆ é™¤äº†
            delete_document(index, relative_path)?;
        }
    }

    Ok(())
}

// ============================================================================
// 7. æ•°æ®åº“é˜Ÿåˆ—è¾…åŠ©å‡½æ•°
// ============================================================================

/// å¤„ç†æ•°æ®åº“ä¸­æ‰€æœ‰å¾…å¤„ç†çš„ä»»åŠ¡
/// å¤„ç†æ•°æ®åº“ä¸­æ‰€æœ‰å¾…å¤„ç†çš„ä»»åŠ¡
fn process_pending_db_jobs(
    db_pool: &Pool<SqliteConnectionManager>,
    index: &Arc<Index>,
) -> Result<()> {
    let conn = db_pool.get()?;
    
    println!("ğŸ” [ç´¢å¼•Worker] æ£€æŸ¥é—ç•™ä»»åŠ¡...");

    loop {
        // æŸ¥è¯¢ä¸€æ¡å¾…å¤„ç†çš„ä»»åŠ¡
        let job_opt: Option<(i64, String)> = conn
            .query_row(
                "SELECT id, payload FROM indexing_jobs 
                 WHERE status = 'pending' AND retry_count < max_retries
                 ORDER BY created_at ASC LIMIT 1",
                [],
                |row| Ok((row.get(0)?, row.get(1)?)), // [ä¿®å¤] ç›´æ¥åœ¨è¿™é‡Œè¿”å› String
            )
            .optional()?;

        match job_opt {
            Some((id, payload_json)) => { // [ä¿®å¤] payload_json ç°åœ¨æ˜¯ String ç±»å‹
                println!("ğŸ” [ç´¢å¼•Worker] å¤„ç†é—ç•™ä»»åŠ¡ ID={}", id);

                // ååºåˆ—åŒ–è½½è·
                let payload: JobPayload = serde_json::from_str(&payload_json)?;

                // å¤„ç†ä»»åŠ¡
                let result = process_job(db_pool, index, &payload);

                if let Err(e) = result {
                    eprintln!("âŒ [ç´¢å¼•Worker] é—ç•™ä»»åŠ¡å¤±è´¥ ID={}: {}", id, e);

                    // å¢åŠ é‡è¯•æ¬¡æ•°
                    conn.execute(
                        "UPDATE indexing_jobs 
                         SET retry_count = retry_count + 1,
                             last_error = ?1,
                             updated_at = CURRENT_TIMESTAMP
                         WHERE id = ?2",
                        params![e.to_string(), id],
                    )?;

                    // æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°
                    let retry_count: i32 = conn.query_row(
                        "SELECT retry_count FROM indexing_jobs WHERE id = ?1",
                        params![id],
                        |row| row.get(0),
                    )?;

                    let max_retries: i32 = conn.query_row(
                        "SELECT max_retries FROM indexing_jobs WHERE id = ?1",
                        params![id],
                        |row| row.get(0),
                    )?;

                    if retry_count >= max_retries {
                        conn.execute(
                            "UPDATE indexing_jobs 
                             SET status = 'failed',
                                 updated_at = CURRENT_TIMESTAMP
                             WHERE id = ?1",
                            params![id],
                        )?;
                        eprintln!("âš ï¸ [ç´¢å¼•Worker] ä»»åŠ¡ ID={} å·²æ ‡è®°ä¸ºå¤±è´¥", id);
                    }
                } else {
                    // æˆåŠŸååˆ é™¤ä»»åŠ¡
                    delete_job_from_db(db_pool, id)?;
                    println!("âœ… [ç´¢å¼•Worker] é—ç•™ä»»åŠ¡å®Œæˆ ID={}", id);
                }
            }
            None => {
                println!("âœ… [ç´¢å¼•Worker] æ‰€æœ‰é—ç•™ä»»åŠ¡å¤„ç†å®Œæˆ");
                break;
            }
        }
    }

    Ok(())
}

/// æŒä¹…åŒ–å¤±è´¥çš„ä»»åŠ¡åˆ°æ•°æ®åº“
/// æŒä¹…åŒ–å¤±è´¥çš„ä»»åŠ¡åˆ°æ•°æ®åº“
fn persist_failed_job_to_db(
    db_pool: &Pool<SqliteConnectionManager>,
    job: &IndexingJob,
    error_msg: &str,
) -> Result<()> {
    let conn = db_pool.get()?;
    let payload_json = serde_json::to_string(&job.payload)?;

    if let Some(id) = job.db_id {
        // æ›´æ–°ç°æœ‰ä»»åŠ¡
        conn.execute(
            "UPDATE indexing_jobs 
             SET retry_count = retry_count + 1,
                 last_error = ?1,
                 updated_at = CURRENT_TIMESTAMP
             WHERE id = ?2",
            params![error_msg, id],
        )?;
    } else {
        // æ’å…¥æ–°ä»»åŠ¡
        conn.execute(
            "INSERT INTO indexing_jobs (payload, status, last_error)
             VALUES (?1, 'pending', ?2)",
            params![payload_json, error_msg],
        )?;
    }

    Ok(())
}

/// ä»æ•°æ®åº“åˆ é™¤å·²å®Œæˆçš„ä»»åŠ¡
fn delete_job_from_db(
    db_pool: &Pool<SqliteConnectionManager>,
    job_id: i64,
) -> Result<()> {
    let conn = db_pool.get()?;
    conn.execute("DELETE FROM indexing_jobs WHERE id = ?1", params![job_id])?;
    Ok(())
}

// ============================================================================
// 8. å…¬å…± APIï¼šå‘é€ç´¢å¼•ä»»åŠ¡
// ============================================================================

/// å‘é€æ›´æ–°/ä¿å­˜ä»»åŠ¡
pub fn dispatch_update_job(root_path: String, relative_path: String) -> Result<()> {
    let payload = JobPayload::UpdateOrSave {
        root_path,
        relative_path,
    };
    
    // [å…³é”®ä¿®æ”¹] å…ˆæŒä¹…åŒ–åˆ°æ•°æ®åº“
    let job_id = persist_job_to_db(&payload)?;
    
    // ç„¶åå‘é€åˆ°å†…å­˜é€šé“
    let job = IndexingJob {
        db_id: Some(job_id),
        payload,
    };
    
    JOB_CHANNEL
        .0
        .send(ControlSignal::Job(job))
        .map_err(|e| anyhow::anyhow!("å‘é€ç´¢å¼•ä»»åŠ¡å¤±è´¥: {}", e))?;

    Ok(())
}

/// å‘é€é‡å‘½åä»»åŠ¡
pub fn dispatch_rename_job(
    root_path: String,
    old_relative_path: String,
    new_relative_path: String,
) -> Result<()> {
    let payload = JobPayload::RenameOrMove {
        root_path,
        old_relative_path,
        new_relative_path,
    };
    
    // [å…³é”®ä¿®æ”¹] å…ˆæŒä¹…åŒ–åˆ°æ•°æ®åº“
    let job_id = persist_job_to_db(&payload)?;
    
    // ç„¶åå‘é€åˆ°å†…å­˜é€šé“
    let job = IndexingJob {
        db_id: Some(job_id),
        payload,
    };

    JOB_CHANNEL
        .0
        .send(ControlSignal::Job(job))
        .map_err(|e| anyhow::anyhow!("å‘é€é‡å‘½åä»»åŠ¡å¤±è´¥: {}", e))?;

    Ok(())
}

/// å‘é€åˆ é™¤ä»»åŠ¡
pub fn dispatch_delete_job(relative_path: String) -> Result<()> {
    let payload = JobPayload::Delete { relative_path };
    
    // [å…³é”®ä¿®æ”¹] å…ˆæŒä¹…åŒ–åˆ°æ•°æ®åº“
    let job_id = persist_job_to_db(&payload)?;
    
    // ç„¶åå‘é€åˆ°å†…å­˜é€šé“
    let job = IndexingJob {
        db_id: Some(job_id),
        payload,
    };

    JOB_CHANNEL
        .0
        .send(ControlSignal::Job(job))
        .map_err(|e| anyhow::anyhow!("å‘é€åˆ é™¤ä»»åŠ¡å¤±è´¥: {}", e))?;

    Ok(())
}
// ============================================================================
// [æ–°å¢] æŒä¹…åŒ–å‡½æ•°
// ============================================================================

/// ç«‹å³æŒä¹…åŒ–ä»»åŠ¡åˆ°æ•°æ®åº“ï¼Œè¿”å›ä»»åŠ¡ID
fn persist_job_to_db(payload: &JobPayload) -> Result<i64> {
    let db_pool_lock = DB_POOL_REF.lock().unwrap();
    let db_pool = db_pool_lock.as_ref()
        .ok_or_else(|| anyhow::anyhow!("æ•°æ®åº“è¿æ¥æ± æœªåˆå§‹åŒ–"))?;
    
    let conn = db_pool.get()?;
    let payload_json = serde_json::to_string(payload)?;
    
    conn.execute(
        "INSERT INTO indexing_jobs (payload, status, retry_count)
         VALUES (?1, 'pending', 0)",
        params![payload_json],
    )?;
    
    let job_id = conn.last_insert_rowid();
    Ok(job_id)
}
