// src-tauri/src/search.rs
// Tantivy å…¨æ–‡æœç´¢å¼•æ“æ¨¡å— - æœ€ç»ˆä¿®å¤ç‰ˆ

use anyhow::{Context, Result};
use once_cell::sync::Lazy;
use serde::{Deserialize, Serialize};
use std::fs;
use std::path::Path;
use std::sync::Arc;
use tantivy::collector::TopDocs;
use tantivy::directory::MmapDirectory;
use tantivy::query::QueryParser;
use tantivy::schema::{Field, IndexRecordOption, Schema, TextFieldIndexing, TextOptions, Value};
use tantivy::tokenizer::{LowerCaser, RemoveLongFilter, TextAnalyzer};
use tantivy::{doc, Index, IndexWriter, ReloadPolicy, TantivyDocument};
use r2d2::Pool;
use r2d2_sqlite::SqliteConnectionManager;
use rusqlite::params;


// (å…¨å±€é™æ€ Jieba åˆ†è¯å™¨ä¿æŒä¸å˜)
static JIEBA_TOKENIZER: Lazy<tantivy_jieba::JiebaTokenizer> = Lazy::new(|| {
    tantivy_jieba::JiebaTokenizer {}
});

// (æœç´¢ç»“æœç»“æ„ä½“ä¿æŒä¸å˜)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SearchResult {
    pub path: String,
    pub title: String,
    pub snippet: String,
}

// (Schema å­—æ®µå®šä¹‰ä¿æŒä¸å˜)
pub struct SchemaFields {
    pub path: Field,
    pub title: Field,
    pub content: Field,
}

/// (åˆ›å»º Schema å‡½æ•°ä¿æŒä¸å˜)
pub fn build_schema() -> (Schema, SchemaFields) {
    let mut schema_builder = Schema::builder();
    
    let path = schema_builder.add_text_field("path", tantivy::schema::STRING | tantivy::schema::STORED);
    
    let text_field_indexing = TextFieldIndexing::default()
        .set_tokenizer("jieba")
        .set_index_option(IndexRecordOption::WithFreqsAndPositions);
    
    let title_options = TextOptions::default()
        .set_indexing_options(text_field_indexing.clone())
        .set_stored();
    let title = schema_builder.add_text_field("title", title_options);
    
    let content_options = TextOptions::default()
        .set_indexing_options(text_field_indexing);
    let content = schema_builder.add_text_field("content", content_options);
    
    let schema = schema_builder.build();
    let fields = SchemaFields { path, title, content };
    
    (schema, fields)
}

// (åˆå§‹åŒ–æˆ–æ‰“å¼€ Tantivy ç´¢å¼•å‡½æ•°ä¿æŒä¸å˜)
pub fn initialize_index(base_path: &Path) -> Result<Arc<Index>> {
    let index_path = base_path.join(".cheetah_index");
    
    if !index_path.exists() {
        fs::create_dir_all(&index_path)
            .with_context(|| format!("åˆ›å»ºç´¢å¼•ç›®å½•å¤±è´¥: {}", index_path.display()))?;
    }
    
    let (schema, _) = build_schema();
    
    let index = if index_path.join("meta.json").exists() {
        let dir = MmapDirectory::open(&index_path)
            .with_context(|| format!("æ‰“å¼€ç´¢å¼•ç›®å½•å¤±è´¥: {}", index_path.display()))?;
        Index::open(dir)
            .with_context(|| "æ‰“å¼€ç°æœ‰ç´¢å¼•å¤±è´¥")?
    } else {
        let dir = MmapDirectory::open(&index_path)
            .with_context(|| format!("åˆ›å»ºç´¢å¼•ç›®å½•å¤±è´¥: {}", index_path.display()))?;
    
		Index::open_or_create(dir, schema.clone()).with_context(|| "åˆ›å»ºç´¢å¼•å¤±è´¥")?
    };
    
    let analyzer = TextAnalyzer::builder(JIEBA_TOKENIZER.clone())
        .filter(RemoveLongFilter::limit(40))
        .filter(LowerCaser)
        .build();
    
    index.tokenizers().register("jieba", analyzer);
    
    println!("âœ… Tantivy ç´¢å¼•å·²åˆå§‹åŒ–: {}", index_path.display());
    
    Ok(Arc::new(index))
}


/// é€’å½’ç´¢å¼•æ‰€æœ‰ Markdown æ–‡ä»¶ï¼Œå¹¶åŒæ­¥å†™å…¥å…ƒæ•°æ®æ•°æ®åº“
pub fn index_documents(
    index: &Index,
    db_pool: &Pool<SqliteConnectionManager>,
    base_path: &Path,
) -> Result<()> {
    let (_, fields) = build_schema();
    
    let conn = db_pool.get().with_context(|| "ä»æ± ä¸­è·å–æ•°æ®åº“è¿æ¥å¤±è´¥")?;

    let mut index_writer: IndexWriter = index
        .writer(50_000_000)
        .with_context(|| "åˆ›å»ºç´¢å¼•å†™å…¥å™¨å¤±è´¥")?;
    
    index_writer.delete_all_documents()
        .with_context(|| "æ¸…ç©ºå…¨æ–‡ç´¢å¼•å¤±è´¥")?;

    conn.execute("DELETE FROM files", [])
        .with_context(|| "æ¸…ç©º files è¡¨å¤±è´¥")?;
    
    let mut count = 0;
    index_directory_recursive(&mut index_writer, &conn, &fields, base_path, &mut count)?;
    
    index_writer.commit()
        .with_context(|| "æäº¤å…¨æ–‡ç´¢å¼•å¤±è´¥")?;
    
    println!("âœ… æ–‡ä»¶ç´¢å¼•ä¸æ•°æ®åº“åŒæ­¥å®Œæˆï¼Œå…±å¤„ç† {} ä¸ªæ–‡ä»¶", count);
    Ok(())
}


/// é€’å½’éå†ç›®å½•å¹¶ç´¢å¼•æ–‡ä»¶
fn index_directory_recursive(
    writer: &mut IndexWriter,
    conn: &r2d2::PooledConnection<SqliteConnectionManager>,
    fields: &SchemaFields,
    dir: &Path,
    count: &mut usize,
) -> Result<()> {
    let entries = fs::read_dir(dir)
        .with_context(|| format!("è¯»å–ç›®å½•å¤±è´¥: {}", dir.display()))?;
    
    for entry in entries {
        let entry = entry?;
        let path = entry.path();
        
        if let Some(name) = path.file_name() {
            let name_str = name.to_string_lossy();
            if name_str.starts_with('.') {
                continue;
            }
        }
        
        let metadata = entry.metadata()?;
        
        if metadata.is_dir() {
            index_directory_recursive(writer, conn, fields, &path, count)?;
        } else if path.extension().and_then(|s| s.to_str()) == Some("md") {
            index_single_document(writer, conn, fields, &path)?;
            *count += 1;
        }
    }
    
    Ok(())
}


/// ç´¢å¼•å•ä¸ªæ–‡æ¡£ï¼Œå¹¶å°†å…¶å…ƒæ•°æ®å†™å…¥æ•°æ®åº“
pub fn index_single_document(
    writer: &mut IndexWriter,
    conn: &r2d2::PooledConnection<SqliteConnectionManager>,
    fields: &SchemaFields,
    file_path: &Path,
) -> Result<()> {
    let content = fs::read_to_string(file_path)
        .with_context(|| format!("è¯»å–æ–‡ä»¶å¤±è´¥: {}", file_path.display()))?;
    
    let title = extract_title_from_content(&content)
        .unwrap_or_else(|| {
            file_path
                .file_stem()
                .and_then(|s| s.to_str())
                .unwrap_or("æ— æ ‡é¢˜")
                .to_string()
        });
    
    let path_str = file_path.to_string_lossy().to_string();
    
    let path_term = tantivy::Term::from_field_text(fields.path, &path_str);
    writer.delete_term(path_term);
    
    let doc = doc!(
        fields.path => path_str.clone(),
        fields.title => title.clone(),
        fields.content => content
    );
    
    writer.add_document(doc)
        .with_context(|| format!("ç´¢å¼•æ–‡æ¡£å¤±è´¥: {}", file_path.display()))?;

    conn.execute(
        "INSERT OR IGNORE INTO files (path, title) VALUES (?1, ?2)",
        params![path_str, title],
    ).with_context(|| format!("å‘æ•°æ®åº“æ’å…¥å…ƒæ•°æ®å¤±è´¥: {}", file_path.display()))?;
    
    Ok(())
}

/// æ›´æ–°å•ä¸ªæ–‡ä»¶çš„ç´¢å¼•
pub fn update_document_index(index: &Index, file_path: &Path) -> Result<()> {
    let (_, fields) = build_schema();
    let mut writer: IndexWriter = index.writer(20_000_000)?;

    // ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬æš‚æ—¶ä¸åœ¨è¿™é‡ŒåŒæ­¥æ•°æ®åº“ï¼Œå› ä¸ºæ¯æ¬¡é‡å¯éƒ½ä¼šå®Œå…¨åŒæ­¥
    // å¹¶ä¸”æ–°å»ºæ–‡ä»¶æ—¶å·²ç»åœ¨ fs.rs ä¸­å†™å…¥äº†æ•°æ®åº“
    // æ›´æ–°æ–‡ä»¶æ—¶ï¼Œå…ƒæ•°æ®ï¼ˆè·¯å¾„/æ ‡é¢˜ï¼‰ä¸€èˆ¬ä¸å˜ï¼Œæ‰€ä»¥ä¹Ÿæš‚æ—¶æ— éœ€æ›´æ–°
    
    let content = fs::read_to_string(file_path).with_context(|| format!("è¯»å–æ–‡ä»¶å¤±è´¥: {}", file_path.display()))?;
    let title = extract_title_from_content(&content).unwrap_or_else(|| file_path.file_stem().and_then(|s| s.to_str()).unwrap_or("æ— æ ‡é¢˜").to_string());
    let path_str = file_path.to_string_lossy().to_string();

    let path_term = tantivy::Term::from_field_text(fields.path, &path_str);
    writer.delete_term(path_term);

    let doc = doc!(
        fields.path => path_str,
        fields.title => title,
        fields.content => content
    );

    writer.add_document(doc).with_context(|| format!("ç´¢å¼•æ–‡æ¡£å¤±è´¥: {}", file_path.display()))?;
    writer.commit()?;
    Ok(())
}

/// ä»ç´¢å¼•ä¸­åˆ é™¤æ–‡æ¡£
pub fn delete_document(index: &Index, file_path: &str) -> Result<()> {
    let (_, fields) = build_schema();
    
    let mut writer: IndexWriter = index.writer(20_000_000)
        .with_context(|| "åˆ›å»ºç´¢å¼•å†™å…¥å™¨å¤±è´¥")?;
    
    let path_term = tantivy::Term::from_field_text(fields.path, file_path);
    writer.delete_term(path_term);
    
    writer.commit()
        .with_context(|| format!("åˆ é™¤æ–‡æ¡£å¤±è´¥: {}", file_path))?;
    
    println!("âœ… å·²ä»ç´¢å¼•ä¸­åˆ é™¤: {}", file_path);
    Ok(())
}

/// å®‰å…¨åœ°æˆªå–å­—ç¬¦ä¸²
fn safe_truncate(s: &str, max_chars: usize) -> String {
    s.chars().take(max_chars).collect()
}


/// æ‰§è¡Œæœç´¢
pub fn search(index: &Index, query: &str) -> Result<Vec<SearchResult>> {
    if query.trim().is_empty() {
        return Ok(Vec::new());
    }
    
    let (_, fields) = build_schema();
    
    let reader = index
        .reader_builder()
        .reload_policy(ReloadPolicy::OnCommitWithDelay)
        .try_into()
        .with_context(|| "åˆ›å»ºç´¢å¼•è¯»å–å™¨å¤±è´¥")?;
    
    let searcher = reader.searcher();
    
    let query_parser = QueryParser::for_index(
        index,
        vec![fields.title, fields.content],
    );
    
    let parsed_query = query_parser
        .parse_query(query)
        .with_context(|| format!("è§£ææŸ¥è¯¢å¤±è´¥: {}", query))?;
    
    let top_docs = searcher
        .search(&parsed_query, &TopDocs::with_limit(10))
        .with_context(|| "æ‰§è¡Œæœç´¢å¤±è´¥")?;
    
    let mut results = Vec::new();
    
    for (_score, doc_address) in top_docs {
        let retrieved_doc: TantivyDocument = match searcher.doc(doc_address) {
            Ok(doc) => doc,
            Err(e) => {
                eprintln!("è·å–æ–‡æ¡£å¤±è´¥: {}", e);
                continue;
            }
        };
        
        let path = retrieved_doc
            .get_first(fields.path)
            .and_then(|v| v.as_str())
            .unwrap_or("")
            .to_string();
		
        let title = retrieved_doc
            .get_first(fields.title)
            .and_then(|v| v.as_str())
            .unwrap_or("æ— æ ‡é¢˜")
            .to_string();
        
        if path.is_empty() {
            continue;
        }
        
        let content = fs::read_to_string(&path).unwrap_or_else(|_| "".to_string());
        
        let snippet = if content.chars().count() > 150 {
            format!("{}...", safe_truncate(&content, 150))
        } else {
            content
        };
        
        results.push(SearchResult {
            path,
            title,
            snippet,
        });
    }
    
    println!("ğŸ” æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {} ä¸ªç»“æœ", results.len());
    Ok(results)
}

/// ä» Markdown å†…å®¹ä¸­æå–æ ‡é¢˜
fn extract_title_from_content(content: &str) -> Option<String> {
    for line in content.lines() {
        let trimmed = line.trim();
        if trimmed.starts_with("# ") {
            return Some(trimmed[2..].trim().to_string());
        }
    }
    None
}